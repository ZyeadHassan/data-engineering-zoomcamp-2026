# üöñ Data Engineering Zoomcamp 2026 - Master Repository

Welcome to my comprehensive data engineering journey! This repository documents my hands-on projects and technical solutions for the **Data Engineering Zoomcamp 2026**.

As a **Data Engineer**, I am building this repository to showcase the implementation of modern data stack technologies in building scalable and efficient data pipelines.

---

## üõ†Ô∏è The Data Engineering Stack

This project leverages a diverse set of tools to cover the entire data lifecycle:

* **Infrastructure as Code (IaC):** **Terraform** for automated provisioning of cloud resources like GCS and BigQuery.
* **Containerization:** **Docker** and **Docker Compose** for consistent environment orchestration and isolation.
* **Workflow Orchestration:** Implementing tools like **Kestra** to manage and schedule complex ETL/ELT pipelines.
* **Data Warehouse:** **Google BigQuery** for high-performance analytics, focusing on cost-efficiency through partitioning and clustering.
* **Data Lake:** **Google Cloud Storage (GCS)** for scalable and reliable storage of raw and processed data.
* **Analytics Engineering:** **dbt (data build tool)** for transforming and modeling data using SQL within the warehouse.
* **Batch & Stream Processing:** **Apache Spark** for large-scale distributed processing and **Apache Kafka** for real-time data streaming.
* **Languages:** **Python** for automation scripts and **SQL** for advanced data analysis and transformations.



---

## üìÇ Project Structure

The repository is organized into modules, each focusing on a specific pillar of Data Engineering:

* **[Module 01: Containerization & IaC](./01-docker-terraform/):** Setting up the foundation with Docker, Terraform, and PostgreSQL.
* **[Module 02: Workflow Orchestration](https://github.com/ZyeadHassan/data-engineering-zoomcamp-2026/tree/main/02-workflow-orchestration):** Automating data ingestion and movement to the cloud.
* **[Module 03: Data Warehouse](https://github.com/ZyeadHassan/data-engineering-zoomcamp-2026/tree/main/Module%203%3A%20Data%20Warehouse%20(BigQuery)):** Deep dive into BigQuery optimization, performance tuning, and cost management.
* **[Module 04: Analytics Engineering](./04-analytics-engineering/):** Data modeling and documentation using dbt.
* **[Module 05: Batch Processing](./05-batch-processing/):** Distributed computing concepts and processing with Apache Spark.
* **
---
## üöÄ Key Learning Objectives

* **End-to-End Pipeline Architecture:** Building robust pipelines on **Google Cloud Platform (GCP)**.
* **Cost & Performance Optimization:** Using **Partitioning** and **Clustering** to minimize cloud costs.
* **Automated Infrastructure:** Managing cloud environments through **Infrastructure as Code (IaC)**.
* **Data Modeling:** Bridging the gap between raw storage and actionable business insights.

---

## üë®‚Äçüè´ About Me
I am a dedicated professional with a background in **Industrial Engineering**. Currently, I share my passion for data as a **Data Analysis Instructor** at the **Information Technology Institute (ITI)**, specializing in SQL, Power BI, and Data Engineering practices.
---

*Developed by Zyead Hassan*
